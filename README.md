# 2D-Human-Pose-Estimators-Strenghts-and-Caveats

## Introduction
Perform a deeper analysis of your model on the validation set of the COCO Keypoint Detection Task 2017.

To perform this deeper analysis the COCO validation set corrected the occlusion labelling and added new labels. The new labels added are:
- Occlusion types (per keypoint):
  - Self occlusion
  - Other person occlusion
  - Environment occlusion
- Truncation by the image border (per person)
- Person resolution (per person)
- Wrong annotations

## Setup
- Download person_keypoints_val2017.json and 2017 Val images from https://cocodataset.org/#download. And put these in the coco/data folder (unzipped version of 2017 Val images).
- Get the models from https://drive.google.com/drive/u/0/folders/1J0S0F9Oto_GJWsSeZPrezgrwUPDZovy_, or download the models directly from the source https://github.com/leoxiaobin/deep-high-resolution-net.pytorch, https://github.com/HRNet/DEKR, https://github.com/ilovepose/DarkPose and put these in the models folder

## About the labels
Note: the example images contain the original labels.

**Occlusion** <br />
The occlusion labels are corrected, because many occlusion labels are inaccurate:
![image](https://user-images.githubusercontent.com/63635825/174550627-655c1f68-94ff-4082-8ecc-f2267b36bfba.png)

**Occlusion types** <br />
There are different ways keypoints can be occluded. We separated these ways by three categories: self occlusion, other person occlusion and environment occlusion which are respectively shown below. The COCO 

**Self occlusion** <br />
The COCO dataset only counts other person occlusion and environment occlusion as occlusion, but self occlusion can also lead to worse performance. Hence, self occlusion is also added.
![image](https://user-images.githubusercontent.com/63635825/174561185-12ed0ce6-51e4-4aa7-99c1-a286bcf2954f.png)


**Other person occlusion** <br />
Other person occlusion are keypoints occluded by other people.
![image](https://user-images.githubusercontent.com/63635825/174561216-06fe3630-ec6a-4169-acd5-a41e6497f833.png)


**Environment occlusion** <br />
This type of occlusion is any type of occlusion which is not self- or other person-occlusion. Hence, any object, helmet, blanket, etc.
![image](https://user-images.githubusercontent.com/63635825/174561247-0d6bd9e7-4671-4105-bd4e-c93f30c36c6c.png)


**Truncation by the image border** <br />
Truncation by the image border happens when the image is cutoff in such a way such that only a subset of the person is present in the image.
![image](https://user-images.githubusercontent.com/63635825/174556198-6838f68e-d00c-4dc4-8432-adb1065470bb.png)

**Person resolution examples** <br />
These are calculated by taking the area of a bounding box generated by the minimum and maximum coordinates of the keypoints.
![image](https://user-images.githubusercontent.com/63635825/177355555-47c7ccad-f58b-4426-8ac7-d40f1d221bcc.png)

**Wrong annotations** <br />
The COCO validation set contains a lot of wrong annotations. From the validation set 107 people are removed to get a more accurate performance measure. These mistakes consist of wrong keypoint mappings, labelling of objects and wrong people mapping. The latter contains the right keypoints, but leads to problems during the evaluation phase. Since, the Euclidian distance is used during the evaluation between the ground truth keypoints and the predicted keypoints on the segmented person.
![image](https://user-images.githubusercontent.com/63635825/174558124-f4b864c1-a65f-4be0-8b29-6445c80e2085.png)

## Results
Results gathered for:
- ResNet-152
- HRNet-W48
- DEKR-W48 (with multi-scale test)
- HRNet-W48 + DarkPose


### General results 
on the validation set where the wrong annotations are removed
| Method       | Input size   |       AP |     AP50 |     AP75 |       AR |     AR50 |     AR75 |
|:-------------|:-------------|---------:|---------:|---------:|---------:|---------:|---------:|
| ResNet-152   | 384x288      | 0.751505 | 0.905256 | 0.820931 | 0.805172 | 0.945236 | 0.867574 |
| HRNet-W48    | 384x288      | 0.771137 | 0.914165 | 0.836741 | 0.820128 | 0.949079 | 0.879424 |
| DEKR-W48 ms  | 640x640      | 0.731873 | 0.891634 | 0.796248 | 0.786357 | 0.934347 | 0.842914 |
| DarkPose-W48 | 384x288      | 0.777486 | 0.913642 | 0.842689 | 0.825348 | 0.949079 | 0.883907 |

### Occlusion results
| Method       | Input size   | Variable   |       AP |     AP50 |     AP75 |       AR |     AR50 |     AR75 |
|:-------------|:-------------|:-----------|---------:|---------:|---------:|---------:|---------:|---------:|
| ResNet-152   | 384x288      | Visible    | 0.793907 | 0.915188 | 0.855816 | 0.846746 | 0.955327 | 0.90053  |
| ResNet-152   | 384x288      | Occluded   | 0.553652 | 0.802815 | 0.577413 | 0.666121 | 0.878248 | 0.693696 |
| HRNet-W48    | 384x288      | Visible    | 0.811359 | 0.92213  | 0.869459 | 0.858894 | 0.956452 | 0.908404 |
| HRNet-W48    | 384x288      | Occluded   | 0.576089 | 0.825418 | 0.610589 | 0.684528 | 0.891001 | 0.722089 |
| DEKR-W48 ms  | 640x640      | Visible    | 0.7759   | 0.901935 | 0.839204 | 0.829214 | 0.944721 | 0.882693 |
| DEKR-W48 ms  | 640x640      | Occluded   | 0.52957  | 0.781537 | 0.553264 | 0.636501 | 0.852743 | 0.664822 |
| DarkPose-W48 | 384x288      | Visible    | 0.816828 | 0.922587 | 0.872116 | 0.862992 | 0.956773 | 0.910493 |
| DarkPose-W48 | 384x288      | Occluded   | 0.588703 | 0.832977 | 0.623541 | 0.695067 | 0.896054 | 0.733397 |

### Occlusion type results
| Method       | Input size   | Variable    |       AP |     AP50 |     AP75 |       AR |     AR50 |     AR75 |
|:-------------|:-------------|:------------|---------:|---------:|---------:|---------:|---------:|---------:|
| ResNet-152   | 384x288      | Self        | 0.621363 | 0.829359 | 0.670562 | 0.735    | 0.909434 | 0.776887 |
| ResNet-152   | 384x288      | Person      | 0.404563 | 0.618902 | 0.403253 | 0.595062 | 0.812346 | 0.60823  |
| ResNet-152   | 384x288      | Environment | 0.501308 | 0.741727 | 0.515017 | 0.654376 | 0.858058 | 0.679296 |
| HRNet-W48    | 384x288      | Self        | 0.635946 | 0.849325 | 0.689515 | 0.745377 | 0.914623 | 0.790094 |
| HRNet-W48    | 384x288      | Person      | 0.419965 | 0.638699 | 0.423897 | 0.613333 | 0.827984 | 0.635391 |
| HRNet-W48    | 384x288      | Environment | 0.537991 | 0.770601 | 0.566225 | 0.682711 | 0.876734 | 0.71825  |
| DEKR-W48 ms  | 640x640      | Self        | 0.593763 | 0.81145  | 0.642233 | 0.715142 | 0.896226 | 0.760377 |
| DEKR-W48 ms  | 640x640      | Person      | 0.379659 | 0.599039 | 0.373853 | 0.536132 | 0.766255 | 0.541564 |
| DEKR-W48 ms  | 640x640      | Environment | 0.509954 | 0.749835 | 0.523372 | 0.644237 | 0.853789 | 0.670224 |
| DarkPose-W48 | 384x288      | Self        | 0.644577 | 0.84911  | 0.699867 | 0.751887 | 0.917453 | 0.799057 |
| DarkPose-W48 | 384x288      | Person      | 0.428344 | 0.64978  | 0.439524 | 0.628477 | 0.841975 | 0.664198 |
| DarkPose-W48 | 384x288      | Environment | 0.549674 | 0.774589 | 0.580989 | 0.691889 | 0.88047  | 0.727321 |

### Truncation results
presence or absence of any truncation where k is the amount of keypoints truncated by the image border

| Method       | Input size   | Variable   |       AP |     AP50 |     AP75 |       AR |     AR50 |     AR75 |
|:-------------|:-------------|:-----------|---------:|---------:|---------:|---------:|---------:|---------:|
| ResNet-152   | 384x288      | k=0        | 0.778968 | 0.922627 | 0.849675 | 0.8235   | 0.958264 | 0.889969 |
| ResNet-152   | 384x288      | 0<k        | 0.62877  | 0.782579 | 0.683107 | 0.767308 | 0.918639 | 0.821006 |
| HRNet-W48    | 384x288      | k=0        | 0.794857 | 0.929203 | 0.860436 | 0.836614 | 0.960161 | 0.898743 |
| HRNet-W48    | 384x288      | 0<k        | 0.659777 | 0.80929  | 0.717158 | 0.786095 | 0.926529 | 0.83925  |
| DEKR-W48 ms  | 640x640      | k=0        | 0.766318 | 0.917326 | 0.827638 | 0.802727 | 0.943562 | 0.859616 |
| DEKR-W48 ms  | 640x640      | 0<k        | 0.56133  | 0.715192 | 0.617258 | 0.752318 | 0.915187 | 0.808185 |
| DarkPose-W48 | 384x288      | k=0        | 0.801423 | 0.929298 | 0.868269 | 0.842234 | 0.960636 | 0.904672 |
| DarkPose-W48 | 384x288      | 0<k        | 0.665044 | 0.807553 | 0.71771  | 0.790483 | 0.926036 | 0.84073  |

per truncation bin

| Method       | Input size   | Variable   |        AP |     AP50 |      AP75 |       AR |     AR50 |     AR75 |
|:-------------|:-------------|:-----------|----------:|---------:|----------:|---------:|---------:|---------:|
| ResNet-152   | 384x288      | 0<k<5      | 0.726115  | 0.845908 | 0.785603  | 0.848819 | 0.961755 | 0.905512 |
| ResNet-152   | 384x288      | 5<=k<9     | 0.480308  | 0.623222 | 0.52343   | 0.782411 | 0.948617 | 0.843874 |
| ResNet-152   | 384x288      | 9<=k<13    | 0.251709  | 0.350633 | 0.271584  | 0.679058 | 0.853403 | 0.722513 |
| ResNet-152   | 384x288      | 13<=k      | 0.0577563 | 0.104396 | 0.0556403 | 0.58247  | 0.804781 | 0.625498 |
| HRNet-W48    | 384x288      | 0<k<5      | 0.751089  | 0.862462 | 0.815368  | 0.862205 | 0.967379 | 0.922385 |
| HRNet-W48    | 384x288      | 5<=k<9     | 0.513413  | 0.661015 | 0.562549  | 0.8      | 0.948617 | 0.86166  |
| HRNet-W48    | 384x288      | 9<=k<13    | 0.274779  | 0.382049 | 0.289912  | 0.700524 | 0.861257 | 0.743455 |
| HRNet-W48    | 384x288      | 13<=k      | 0.0944583 | 0.156341 | 0.0926355 | 0.618725 | 0.836653 | 0.645418 |
| DEKR-W48 ms  | 640x640      | 0<k<5      | 0.658751  | 0.788095 | 0.71522   | 0.840607 | 0.96063  | 0.897638 |
| DEKR-W48 ms  | 640x640      | 5<=k<9     | 0.376821  | 0.52502  | 0.423596  | 0.757708 | 0.942688 | 0.820158 |
| DEKR-W48 ms  | 640x640      | 9<=k<13    | 0.136964  | 0.203449 | 0.146347  | 0.653927 | 0.850785 | 0.704188 |
| DEKR-W48 ms  | 640x640      | 13<=k      | 0.0296679 | 0.050188 | 0.032078  | 0.578884 | 0.800797 | 0.625498 |
| DarkPose-W48 | 384x288      | 0<k<5      | 0.756507  | 0.860533 | 0.815943  | 0.867942 | 0.965129 | 0.92351  |
| DarkPose-W48 | 384x288      | 5<=k<9     | 0.519367  | 0.659881 | 0.562645  | 0.802767 | 0.94664  | 0.853755 |
| DarkPose-W48 | 384x288      | 9<=k<13    | 0.282939  | 0.387292 | 0.298649  | 0.703927 | 0.861257 | 0.751309 |
| DarkPose-W48 | 384x288      | 13<=k      | 0.095229  | 0.154895 | 0.0935694 | 0.624303 | 0.844622 | 0.661355 |

### Image resolution
Image resolution per person categorized as Low (pixels < 32^2), Medium (32^2 <= pixels < 96^2) and High (96^2 <= pixels)

| Method       | Input size   | Variable   |       AP |     AP50 |     AP75 |       AR |     AR50 |     AR75 |
|:-------------|:-------------|:-----------|---------:|---------:|---------:|---------:|---------:|---------:|
| ResNet-152   | 384x288      | Low        | 0.215078 | 0.337291 | 0.231345 | 0.598812 | 0.826603 | 0.653207 |
| ResNet-152   | 384x288      | Medium     | 0.695458 | 0.85851  | 0.765914 | 0.770674 | 0.928595 | 0.839256 |
| ResNet-152   | 384x288      | High       | 0.816666 | 0.936762 | 0.881864 | 0.87402  | 0.981468 | 0.930862 |
| HRNet-W48    | 384x288      | Low        | 0.23106  | 0.356074 | 0.246948 | 0.626366 | 0.840855 | 0.68171  |
| HRNet-W48    | 384x288      | Medium     | 0.71366  | 0.871927 | 0.783937 | 0.783826 | 0.932248 | 0.851876 |
| HRNet-W48    | 384x288      | High       | 0.837119 | 0.946224 | 0.895505 | 0.888881 | 0.983963 | 0.939416 |
| DEKR-W48 ms  | 640x640      | Low        | 0.197768 | 0.321885 | 0.211937 | 0.555819 | 0.790974 | 0.605701 |
| DEKR-W48 ms  | 640x640      | Medium     | 0.686658 | 0.863043 | 0.754625 | 0.746762 | 0.920292 | 0.810694 |
| DEKR-W48 ms  | 640x640      | High       | 0.789592 | 0.905398 | 0.847347 | 0.863792 | 0.97149  | 0.9134   |
| DarkPose-W48 | 384x288      | Low        | 0.237823 | 0.360732 | 0.253245 | 0.630166 | 0.845606 | 0.691211 |
| DarkPose-W48 | 384x288      | Medium     | 0.717907 | 0.870932 | 0.787628 | 0.788675 | 0.932913 | 0.855862 |
| DarkPose-W48 | 384x288      | High       | 0.844777 | 0.946202 | 0.900619 | 0.895082 | 0.98325  | 0.944048 |
